{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Entrenamiento_Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO PROCESADO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Cargar datos desde la carpeta data/raw\n",
    "data_path = '../data/raw/Housing.csv'\n",
    "housing_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format and drop it from correlation calculations\n",
    "housing_df['date'] = pd.to_datetime(housing_df['date'], errors='coerce')\n",
    "\n",
    "# Recalculate the correlation matrix without the 'date' column\n",
    "correlation_matrix_cleaned = housing_df.drop(columns=['date']).corr(numeric_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Squared Error': np.float64(0.018635396545462143),\n",
       " 'Mean Absolute Error': np.float64(0.08623188026039275),\n",
       " 'R-squared': 0.8643915548286348}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront','view','condition','grade',\n",
    "            'sqft_above', 'sqft_basement','yr_built','yr_renovated','zipcode','lat','long','sqft_living15', 'sqft_lot15']\n",
    "\n",
    "X = correlation_matrix_cleaned[features]\n",
    "y = correlation_matrix_cleaned['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Guardar los conjuntos de entrenamiento\n",
    "X_train.to_csv('../data/train/X_train_np.csv', index=False)\n",
    "y_train.to_csv('../data/train/y_train_np.csv', index=False)\n",
    "\n",
    "# Guardar los conjuntos de prueba\n",
    "X_test.to_csv('../data/test/X_test_np.csv', index=False)\n",
    "y_test.to_csv('../data/test/y_test_np.csv', index=False)\n",
    "\n",
    "# Initialize and train a Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output evaluation metrics\n",
    "{\n",
    "    \"Mean Squared Error\": mse,\n",
    "    \"Mean Absolute Error\": mae,\n",
    "    \"R-squared\": r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Squared Error': np.float64(0.003436679220912177),\n",
       " 'Mean Absolute Error': np.float64(0.05321871101699846),\n",
       " 'R-squared': 0.9238469806028873}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront','view','condition','grade',\n",
    "            'sqft_above', 'sqft_basement','yr_built','yr_renovated','zipcode','lat','long','sqft_living15', 'sqft_lot15']\n",
    "\n",
    "X = correlation_matrix_cleaned[features]\n",
    "y = correlation_matrix_cleaned['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95)\n",
    "\n",
    "# Initialize and train a Linear Regression model\n",
    "model= RandomForestRegressor(max_depth=None, min_samples_leaf= 1 , min_samples_split=2, n_estimators=1978,random_state=95)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output evaluation metrics\n",
    "{\n",
    "    \"Mean Squared Error\": mse,\n",
    "    \"Mean Absolute Error\": mae,\n",
    "    \"R-squared\": r2\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'final_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ensemble Mean Squared Error': np.float64(0.0822802741517641),\n",
       " 'Ensemble Mean Absolute Error': np.float64(0.2238507010331222),\n",
       " 'Ensemble R-squared': 0.7074266878838917}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "\n",
    "# Initialize individual models\n",
    "linear_model = LinearRegression()\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=1000)\n",
    "gb_model = GradientBoostingRegressor(random_state=42, n_estimators=1000)\n",
    "\n",
    "# Create a Voting Regressor ensemble model\n",
    "ensemble_model = VotingRegressor(estimators=[('linear', linear_model), ('rf', rf_model), ('gb', gb_model)])\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate on the test set\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_mse = mean_squared_error(y_test, y_pred_ensemble)\n",
    "ensemble_mae = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "ensemble_r2 = r2_score(y_test, y_pred_ensemble)\n",
    "\n",
    "# Output evaluation metrics for the ensemble model\n",
    "{\n",
    "    \"Ensemble Mean Squared Error\": ensemble_mse,\n",
    "    \"Ensemble Mean Absolute Error\": ensemble_mae,\n",
    "    \"Ensemble R-squared\": ensemble_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Squared Error': np.float64(0.10298155734664377),\n",
       " 'Mean Absolute Error': np.float64(0.2548916567404886),\n",
       " 'R-squared': 0.6387002277341265}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# Cargar datos desde la carpeta data/raw\n",
    "data_path = '../data/processed/Housing_Processed.csv'\n",
    "housing_df_cleaned = pd.read_csv(data_path)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living_log', 'sqft_lot', 'floors', \n",
    "            'view', 'grade', 'sqft_above', 'sqft_basement', \n",
    "            'sqft_living15', 'sqft_lot15', 'property_age']\n",
    "\n",
    "X = housing_df_cleaned[features]\n",
    "y = housing_df_cleaned['price_log']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Guardar los conjuntos de entrenamiento\n",
    "X_train.to_csv('../data/train/X_train.csv', index=False)\n",
    "y_train.to_csv('../data/train/y_train.csv', index=False)\n",
    "\n",
    "# Guardar los conjuntos de prueba\n",
    "X_test.to_csv('../data/test/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/test/y_test.csv', index=False)\n",
    "\n",
    "# Initialize and train a Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output evaluation metrics\n",
    "{\n",
    "    \"Mean Squared Error\": mse,\n",
    "    \"Mean Absolute Error\": mae,\n",
    "    \"R-squared\": r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ensemble Mean Squared Error': np.float64(0.020272569932903065),\n",
       " 'Ensemble Mean Absolute Error': np.float64(0.0981695671043486),\n",
       " 'Ensemble R-squared': 0.5507822196684611}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "\n",
    "# Initialize individual models\n",
    "linear_model = LinearRegression()\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=1000)\n",
    "gb_model = GradientBoostingRegressor(random_state=42, n_estimators=1000)\n",
    "\n",
    "# Create a Voting Regressor ensemble model\n",
    "ensemble_model = VotingRegressor(estimators=[('linear', linear_model), ('rf', rf_model), ('gb', gb_model)])\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate on the test set\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_mse = mean_squared_error(y_test, y_pred_ensemble)\n",
    "ensemble_mae = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "ensemble_r2 = r2_score(y_test, y_pred_ensemble)\n",
    "\n",
    "# Output evaluation metrics for the ensemble model\n",
    "{\n",
    "    \"Ensemble Mean Squared Error\": ensemble_mse,\n",
    "    \"Ensemble Mean Absolute Error\": ensemble_mae,\n",
    "    \"Ensemble R-squared\": ensemble_r2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Best Random Forest Parameters': {'max_depth': 30,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 200},\n",
       " 'Best Gradient Boosting Parameters': {'learning_rate': 0.1,\n",
       "  'max_depth': 7,\n",
       "  'n_estimators': 100},\n",
       " 'Best Random Forest Model': RandomForestRegressor(max_depth=30, min_samples_split=10, n_estimators=200,\n",
       "                       random_state=42),\n",
       " 'Best Gradient Boosting Model': GradientBoostingRegressor(max_depth=7, random_state=42)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for Random Forest and Gradient Boosting\n",
    "\n",
    "# Redefine the parameter grids and grid searches for Random Forest and Gradient Boosting\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Set up grid search for Random Forest\n",
    "rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "# Set up grid search for Gradient Boosting\n",
    "gb_grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), gb_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "best_gb = gb_grid_search.best_estimator_\n",
    "\n",
    "# Output the best parameters and models for each search\n",
    "{\n",
    "    \"Best Random Forest Parameters\": rf_grid_search.best_params_,\n",
    "    \"Best Gradient Boosting Parameters\": gb_grid_search.best_params_,\n",
    "    \"Best Random Forest Model\": best_rf,\n",
    "    \"Best Gradient Boosting Model\": best_gb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Voting Regressor ensemble with the best models and a Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('linear', linear_model), \n",
    "    ('rf', best_rf), \n",
    "    ('gb', best_gb)\n",
    "])\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate on the test set\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_mse = mean_squared_error(y_test, y_pred_ensemble)\n",
    "ensemble_mae = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "ensemble_r2 = r2_score(y_test, y_pred_ensemble)\n",
    "\n",
    "# Output evaluation metrics for the updated ensemble model\n",
    "{\n",
    "    \"Ensemble Mean Squared Error\": ensemble_mse,\n",
    "    \"Ensemble Mean Absolute Error\": ensemble_mae,\n",
    "    \"Ensemble R-squared\": ensemble_r2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XGBoost library\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "\n",
    "# Train the XGBoost model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Create a new Voting Regressor ensemble with the best models and the XGBoost model\n",
    "ensemble_model_xgb = VotingRegressor(estimators=[\n",
    "    ('linear', LinearRegression()), \n",
    "    ('rf', best_rf), \n",
    "    ('gb', best_gb),\n",
    "    ('xgb', xgb_model)\n",
    "])\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "ensemble_model_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions and evaluate on the test set\n",
    "y_pred_ensemble_xgb = ensemble_model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model with XGBoost\n",
    "ensemble_mse_xgb = mean_squared_error(y_test, y_pred_ensemble_xgb)\n",
    "ensemble_mae_xgb = mean_absolute_error(y_test, y_pred_ensemble_xgb)\n",
    "ensemble_r2_xgb = r2_score(y_test, y_pred_ensemble_xgb)\n",
    "\n",
    "# Output evaluation metrics for the ensemble model with XGBoost\n",
    "{\n",
    "    \"Ensemble with XGBoost Mean Squared Error\": ensemble_mse_xgb,\n",
    "    \"Ensemble with XGBoost Mean Absolute Error\": ensemble_mae_xgb,\n",
    "    \"Ensemble with XGBoost R-squared\": ensemble_r2_xgb\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up grid search for XGBoost\n",
    "xgb_grid_search = GridSearchCV(XGBRegressor(objective='reg:squarederror', random_state=42), \n",
    "                               xgb_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best estimator and parameters\n",
    "best_xgb = xgb_grid_search.best_estimator_\n",
    "best_xgb_params = xgb_grid_search.best_params_\n",
    "\n",
    "# Output the best parameters for XGBoost\n",
    "{\n",
    "    \"Best XGBoost Parameters\": best_xgb_params,\n",
    "    \"Best XGBoost Model\": best_xgb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Voting Regressor ensemble with the optimized XGBoost and other models\n",
    "ensemble_model_optimized = VotingRegressor(estimators=[\n",
    "    ('linear', LinearRegression()), \n",
    "    ('rf', best_rf), \n",
    "    ('gb', best_gb),\n",
    "    ('xgb', best_xgb)\n",
    "])\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "ensemble_model_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate on the test set\n",
    "y_pred_ensemble_optimized = ensemble_model_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized ensemble model\n",
    "ensemble_mse_optimized = mean_squared_error(y_test, y_pred_ensemble_optimized)\n",
    "ensemble_mae_optimized = mean_absolute_error(y_test, y_pred_ensemble_optimized)\n",
    "ensemble_r2_optimized = r2_score(y_test, y_pred_ensemble_optimized)\n",
    "\n",
    "# Output evaluation metrics for the optimized ensemble model\n",
    "{\n",
    "    \"Optimized Ensemble Mean Squared Error\": ensemble_mse_optimized,\n",
    "    \"Optimized Ensemble Mean Absolute Error\": ensemble_mae_optimized,\n",
    "    \"Optimized Ensemble R-squared\": ensemble_r2_optimized\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
